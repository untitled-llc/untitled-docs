---
id: s3
title: S3
sidebar_label: S3
slug: /esquire/ads_automation/NM/s3
---


The following S3 buckets and folder paths are laid out in the order they appear within the New Mover Ads Automation. This documentation is for a clearer description of what type of files/information each bucket/folder holds. 


1. [*esquire-movers/AVRICK-combined-newmovers-weekly/*](https://s3.console.aws.amazon.com/s3/buckets/esquire-movers?region=us-east-2&prefix=AVRICK-combined-newmovers-weekly/&showversions=false)   -- This holds the orignal file from Avrick. It is a csv file with the columns [*add1, add2, city, st, zip, zip4, dt, keycode2*]. These are all of the addresses for new movers across the United States for the given week. Its file name is **CNM\_ESQUIRE**\_date.csv. (The date format is mmddyyyy).

2. [*esquire-movers/movers-3-month-segment-partitioned/*](https://s3.console.aws.amazon.com/s3/buckets/esquire-movers?region=us-east-2&prefix=movers-3-month-segment-partitioned/&showversions=false)  -- This holds the exact same, orignal Avrick new movers file with the same filename and data included.

3. [*redshift-unload-ads-automation/new-movers/*](https://s3.console.aws.amazon.com/s3/buckets/redshift-unload-ads-automation?region=us-east-2&prefix=new-movers/&showversions=false)  -- This holds the file that has now been updated by the Redshift SQL procedure. It is a csv file with the columns [*combined_address, city, st, zip, zip4, store\_name\__c, child\id\__c, facebook, xandr, el toro, google ads*]. This file is not ever moved from this folder. It is just written over each week. 

4.  [*esquire-onspot-va/input/new*](https://s3.console.aws.amazon.com/s3/buckets/esquire-onspot-va?region=us-east-1&prefix=input/new/&showversions=false) This holds the file that will be used as the input body for the OnSpot API call. It is the same data from the S3 fodler above but split into separate files for each store/child\_id\__c. It holds the columns [*address, city, state, zip, zip-4*]. All of the information that was previously added by the Redshift SQL procedure is now stored in the naming convention of the file. The filename is **store\_name**\_**sf\_id**\_**todaysdate**\_**W#**\_NM\_act\_**fb\_id**\_**xandr\_id**.csv. This file will be moved from */input/new/* folder to the */input/archived/* further along in the process, once it has been used as the input for OnSpot API. 

5. [*esquire-onspot-va/output/new/*](https://s3.console.aws.amazon.com/s3/buckets/esquire-onspot-va?region=us-east-1&prefix=output/new/&showversions=false) This bucket is used as a place for OnSpot to send all responses to the first API call. Esquire sends OnSpot a file including all new mover addresses and OnSpot asynrchronouslly will return a file, with the same file name as the file used as the input (aka same file name as #4) and sends it to this S3 folder path. This file is a csv that contains hashed device IDs, where each hashed device ID is a new line. This file will be moved from */output/new/* to */output/archived/* once it has been copied to the follwing S3 folder (#6). The */output/archived/* bucket will now be used as the input for the second OnSpot API call. OnSpot will find the correct input based upon the filename.


6. [*segment-upload-bucket/NM/*](https://s3.console.aws.amazon.com/s3/buckets/segment-upload-bucket?region=us-east-2&prefix=NM/&showversions=false) This bucket is used to trigger the Xandr and Facebook ads automation Lambda functions. It holds an exact copy of the files from #5, with the same data and filenames. Once the Lambda functions have used this file as a trigger, it will be deleted from this S3 folder path because the other copy of the file will permanently stay in */esquire-onspot-va/output/archived/*.
